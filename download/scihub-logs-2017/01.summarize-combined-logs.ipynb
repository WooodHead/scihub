{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Sci-Hub log data from 2015-2016 and 2017\n",
    "\n",
    "On 2018-01-18, Sci-Hub [Tweeted](https://twitter.com/Sci_Hub/status/954095639859814402):\n",
    "\n",
    "> Sci-Hub download log for 2017 year: http://sci-hub.tw/downloads/2017.statistics.tab two most read 2017 papers are on climate change http://sci-hub.tw/10.1175/JCLI-D-16-0526.1 and obesity http://sci-hub.tw/10.1056/NEJMra1514009.\n",
    "\n",
    "`2017.statistics.tab` was downloaded manually and XZ-compressed with a compression preset of 8. See also a [Zenodo deposit](https://doi.org/10.5281/zenodo.1158301) with a gzip-compressed version of the database.\n",
    "\n",
    "Note that this dataset [does not come](https://twitter.com/dhimmel/status/954455092941516800) with column names. Bastian Greshake Tzovaras [commented](https://twitter.com/gedankenstuecke/status/954460278007083008) regarding the columns with unclear meaning:\n",
    "\n",
    "```\n",
    "to my knowledge:\n",
    "#3: IP address identifier\n",
    "#4: User identifier (prob. cookie based)\n",
    "```\n",
    "\n",
    "See preliminary work by Bastian Greshake Tzovaras in [this tweet](https://twitter.com/gedankenstuecke/status/956329480376717312) and [this gist](https://gist.github.com/gedankenstuecke/c9ad0fb53a586833a9b14ee8b8ba77a8).\n",
    "Here we compute similar summary data on the 2015-2016 log data combined with the log data for 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import collections\n",
    "import csv\n",
    "import itertools\n",
    "import lzma\n",
    "import datetime\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readers for Sci-Hub log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2015_log_rows():\n",
    "    \"\"\"\n",
    "    Return a generator of rows as dicts in scihub-logs_2015-09_2016-02.tsv.xz.\n",
    "    \"\"\"\n",
    "    with lzma.open('../scihub-logs/scihub-logs_2015-09_2016-02.tsv.xz', 'rt') as read_file:\n",
    "        rows = csv.DictReader(read_file, delimiter='\\t')\n",
    "        for row in rows:\n",
    "            try:\n",
    "                for k, v in list(row.items()):\n",
    "                    if v == '':\n",
    "                        row[v] = None\n",
    "                row['doi'] = row['doi'].lower()\n",
    "                row['date'] = datetime.datetime.strptime(row['date'], \"%Y-%m-%d %H:%M:%S\")\n",
    "                yield row\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2017_log_rows():\n",
    "    \"\"\"\n",
    "    Return a generator of rows as dicts in 2017.statistics.tab. Note that column names are not\n",
    "    part of the dataset and are thus inferred.\n",
    "    \"\"\"\n",
    "    columns = 'date', 'doi', 'IP_code', 'user_code', 'country', 'city', 'latitude', 'longitude'\n",
    "    with lzma.open('2017.statistics.tab.xz', 'rt') as read_file:\n",
    "        rows = csv.DictReader(read_file, fieldnames=columns, delimiter='\\t')\n",
    "        for row in rows:\n",
    "            try:\n",
    "                for k, v in list(row.items()):\n",
    "                    if v == 'N/A':\n",
    "                        row[v] = None\n",
    "                row['doi'] = row['doi'].lower()\n",
    "                row['date'] = datetime.datetime.strptime(row['date'], \"%Y-%m-%d %H:%M:%S\")\n",
    "                yield row\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each month, summarize Sci-Hub download activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months in list: 18\n"
     ]
    }
   ],
   "source": [
    "def month_year_iter(start_year, start_month, end_year, end_month):\n",
    "    \"\"\"\n",
    "    Generate year, month tuples spanning the specified range.\n",
    "    Inclusive of start_month and end_month.\n",
    "    Based on https://stackoverflow.com/a/5734564/4651668\n",
    "    \"\"\"\n",
    "    ym_start = 12 * start_year + start_month - 1\n",
    "    ym_end= 12 * end_year + end_month\n",
    "    for ym in range(ym_start, ym_end):\n",
    "        y, m = divmod(ym, 12)\n",
    "        yield y, m + 1\n",
    "\n",
    "year_months = list(month_year_iter(2015, 9, 2016, 2)) + list(month_year_iter(2017, 1, 2017, 12))\n",
    "print('Months in list:', len(year_months))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlies = dict()\n",
    "possible_dates = set()\n",
    "for year, month in year_months:\n",
    "    _, n_calendar_days = calendar.monthrange(year, month)\n",
    "    for day in range(1, 1 + n_calendar_days):\n",
    "        possible_dates.add(datetime.date(year, month, day))\n",
    "    stats = {\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'n_calendar_days': n_calendar_days,\n",
    "        'n_downloads': 0,\n",
    "        'articles': set(),\n",
    "        'visitors': set(),\n",
    "        'log_days': set(),\n",
    "    }\n",
    "    monthlies[(year, month)] = collections.OrderedDict(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days with logs: 494\n"
     ]
    }
   ],
   "source": [
    "logged_dates = set()\n",
    "rows = itertools.chain(get_2015_log_rows(), get_2017_log_rows())\n",
    "for i, row in enumerate(rows):\n",
    "    date = row['date'].date()\n",
    "    logged_dates.add(date)\n",
    "    try:\n",
    "        stats = monthlies[(date.year, date.month)]\n",
    "    except KeyError:\n",
    "        # date out of range\n",
    "        continue\n",
    "    stats['n_downloads'] += 1\n",
    "    stats['articles'].add(row['doi'])\n",
    "    stats['visitors'].add(row['IP_code'])\n",
    "    stats['log_days'].add(date.day)\n",
    "#     if i > 10000:\n",
    "#         break\n",
    "\n",
    "print(f'Days with logs: {len(logged_dates):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stats in monthlies.values():\n",
    "    stats['n_visitors'] = len(stats.pop('visitors'))\n",
    "    stats['n_articles'] = len(stats.pop('articles'))\n",
    "    stats['n_log_days'] = len(stats.pop('log_days'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>n_calendar_days</th>\n",
       "      <th>n_downloads</th>\n",
       "      <th>n_visitors</th>\n",
       "      <th>n_articles</th>\n",
       "      <th>n_log_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>4904318</td>\n",
       "      <td>587565</td>\n",
       "      <td>3067114</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>6072147</td>\n",
       "      <td>760939</td>\n",
       "      <td>3461622</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>1849385</td>\n",
       "      <td>279688</td>\n",
       "      <td>1342836</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3879510</td>\n",
       "      <td>490114</td>\n",
       "      <td>2544046</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4901512</td>\n",
       "      <td>643168</td>\n",
       "      <td>2938775</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>6213091</td>\n",
       "      <td>906221</td>\n",
       "      <td>3740944</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>9257598</td>\n",
       "      <td>1513862</td>\n",
       "      <td>5148169</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>9854264</td>\n",
       "      <td>1564356</td>\n",
       "      <td>5230317</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>12990139</td>\n",
       "      <td>1920146</td>\n",
       "      <td>6418327</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>8911780</td>\n",
       "      <td>1495622</td>\n",
       "      <td>4883206</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>13959687</td>\n",
       "      <td>2050739</td>\n",
       "      <td>6853773</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>14123204</td>\n",
       "      <td>1890142</td>\n",
       "      <td>7022257</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>18410282</td>\n",
       "      <td>2023446</td>\n",
       "      <td>7551163</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>17418110</td>\n",
       "      <td>2079473</td>\n",
       "      <td>8211371</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>15235240</td>\n",
       "      <td>2105887</td>\n",
       "      <td>7192829</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>4071933</td>\n",
       "      <td>811208</td>\n",
       "      <td>2797601</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>15878921</td>\n",
       "      <td>2433576</td>\n",
       "      <td>7751970</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>10764704</td>\n",
       "      <td>1659668</td>\n",
       "      <td>6067799</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  n_calendar_days  n_downloads  n_visitors  n_articles  \\\n",
       "0   2015      9               30      4904318      587565     3067114   \n",
       "1   2015     10               31      6072147      760939     3461622   \n",
       "2   2015     11               30      1849385      279688     1342836   \n",
       "3   2015     12               31      3879510      490114     2544046   \n",
       "4   2016      1               31      4901512      643168     2938775   \n",
       "5   2016      2               29      6213091      906221     3740944   \n",
       "6   2017      1               31      9257598     1513862     5148169   \n",
       "7   2017      2               28      9854264     1564356     5230317   \n",
       "8   2017      3               31     12990139     1920146     6418327   \n",
       "9   2017      4               30      8911780     1495622     4883206   \n",
       "10  2017      5               31     13959687     2050739     6853773   \n",
       "11  2017      6               30     14123204     1890142     7022257   \n",
       "12  2017      7               31     18410282     2023446     7551163   \n",
       "13  2017      8               31     17418110     2079473     8211371   \n",
       "14  2017      9               30     15235240     2105887     7192829   \n",
       "15  2017     10               31      4071933      811208     2797601   \n",
       "16  2017     11               30     15878921     2433576     7751970   \n",
       "17  2017     12               31     10764704     1659668     6067799   \n",
       "\n",
       "    n_log_days  \n",
       "0           30  \n",
       "1           31  \n",
       "2           13  \n",
       "3           30  \n",
       "4           31  \n",
       "5           29  \n",
       "6           31  \n",
       "7           27  \n",
       "8           30  \n",
       "9           21  \n",
       "10          30  \n",
       "11          30  \n",
       "12          31  \n",
       "13          30  \n",
       "14          30  \n",
       "15           8  \n",
       "16          30  \n",
       "17          31  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_df = pandas.DataFrame(list(monthlies.values()))\n",
    "# month_df = month_df.query(\"n_downloads > 0\")\n",
    "month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df.to_csv('monthly-log-summaries.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-11-05\n",
      "2015-11-06\n",
      "2015-11-07\n",
      "2015-11-08\n",
      "2015-11-09\n",
      "2015-11-10\n",
      "2015-11-11\n",
      "2015-11-12\n",
      "2015-11-13\n",
      "2015-11-14\n",
      "2015-11-15\n",
      "2015-11-16\n",
      "2015-11-17\n",
      "2015-11-18\n",
      "2015-11-19\n",
      "2015-11-20\n",
      "2015-11-21\n",
      "2015-12-27\n",
      "2017-02-20\n",
      "2017-03-28\n",
      "2017-04-21\n",
      "2017-04-22\n",
      "2017-04-23\n",
      "2017-04-24\n",
      "2017-04-25\n",
      "2017-04-26\n",
      "2017-04-27\n",
      "2017-04-28\n",
      "2017-04-29\n",
      "2017-05-31\n",
      "2017-08-19\n",
      "2017-10-07\n",
      "2017-10-08\n",
      "2017-10-09\n",
      "2017-10-10\n",
      "2017-10-11\n",
      "2017-10-12\n",
      "2017-10-13\n",
      "2017-10-14\n",
      "2017-10-15\n",
      "2017-10-16\n",
      "2017-10-17\n",
      "2017-10-18\n",
      "2017-10-19\n",
      "2017-10-20\n",
      "2017-10-21\n",
      "2017-10-22\n",
      "2017-10-23\n",
      "2017-10-24\n",
      "2017-10-25\n",
      "2017-10-26\n",
      "2017-10-27\n",
      "2017-10-28\n",
      "2017-10-29\n"
     ]
    }
   ],
   "source": [
    "# Dates without log data\n",
    "for date in sorted(possible_dates - logged_dates):\n",
    "    print(date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scihub]",
   "language": "python",
   "name": "conda-env-scihub-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
